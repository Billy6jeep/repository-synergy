{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, csv, pickle\n",
    "import pandas as pd\n",
    "import scipy as sy\n",
    "import numpy as np\n",
    "import transformers as tr\n",
    "import gensim.downloader as api\n",
    "\n",
    "from collections import Counter\n",
    "from mittens import GloVe, Mittens\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans, SpectralClustering, DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../data/processed/final_repo_english_whatwhy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme = data['content_text_w_o_tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_alpha = readme.apply(lambda x: ' '.join(x for x in x.split() if x.isalpha()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_en = list(stop_words.ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glove vectors for oov are generated by fine tuning. Check bottom of the notebook\n",
    "with open(\"repo_glove.pkl\", 'rb') as f:\n",
    "    repo_glove = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs_list = list(glove_model.vocab.keys()) + list(repo_glove.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs_dict = dict((a,0) for a in vocabs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_tokens = [[token.lower() for token in doc.split() if (token.lower() in vocabs_dict) and (token.lower() not in stop_words_en)] for doc in readme_alpha]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tokens = []\n",
    "for tokens in readme_tokens:\n",
    "    top_tokens.append(list(dict(Counter(tokens).most_common(10)).keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vecs(v):\n",
    "    try:\n",
    "        return glove_model[v]\n",
    "    except KeyError:\n",
    "        return repo_glove[v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_vocab = list({w for v in top_tokens for w in v})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_vecs = [get_vecs(t) for t in tokens_vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters(vocabs, labels):\n",
    "    vocab_clusters = dict(zip(vocabs, labels))\n",
    "    cluster_groups = dict(sorted(vocab_clusters.items(), key=lambda x:x[1]))\n",
    "    return cluster_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_model = KMeans(n_clusters=20, random_state=66)\n",
    "kmeans_model.fit_transform(tokens_vecs)\n",
    "kmeans_groups = get_clusters(tokens_vocab, kmeans_model.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density-Based Spatial Clustering of Applications with Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = DBSCAN(metric=\"cosine\", eps=0.2, min_samples=10)\n",
    "dbs_labels = dbs.fit_predict(tokens_vecs)\n",
    "dbs_groups = get_clusters(tokens_vocab, dbs_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of clusters: {len(set(dbs_labels))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes too long to run the model compared to other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_model = SpectralClustering(n_clusters=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_model.fit(tokens_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_groups = get_clusters(tokens_vocab, spec_model.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spec_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mittens_model = Mittens(n=50, max_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove2dict(glove_filename):\n",
    "    with open(glove_filename, encoding='utf-8') as f:\n",
    "        reader = csv.reader(f, delimiter=' ', quoting=csv.QUOTE_NONE)\n",
    "        embed = {line[0]: np.array(list(map(float, line[1:])))\n",
    "                for line in reader}\n",
    "    return embed\n",
    "\n",
    "glove_path = \"glove.6B\\\\glove.6B.50d.txt\" # get it from https://nlp.stanford.edu/projects/glove\n",
    "original_emb = glove2dict(glove_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freqmorethan(xdict, val):\n",
    "    return [k for (k,v) in Counter(xdict).items() if v<=val]\n",
    "\n",
    "readme_nonstop = [' '.join([token.lower() for token in doc.split() if (token.lower() not in stop_words_en)]) for doc in readme_alpha]\n",
    "oov = [token for doc in readme_nonstop for token in doc.split() if token not in glove_model.vocab]\n",
    "oov_vocab = get_freqmorethan(oov, 1)\n",
    "stops_oov = oov_vocab + stop_words_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_tokens = [[token for token in doc.split() if (token.lower() not in stop_words_en)] for doc in readme_alpha]\n",
    "short_tokens = [[token for token in doc if token not in oov_vocab] for doc in readme_tokens]\n",
    "short_readme = [' '.join(t) for t in short_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_vocab = list(set(oov) - set(oov_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,1), vocabulary=corp_vocab)\n",
    "X = cv.fit_transform(short_readme)\n",
    "Xc = (X.T * X)\n",
    "Xc.setdiag(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coocc_ar = Xc.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_embeddings = mittens_model.fit(\n",
    "    coocc_ar,\n",
    "    vocab=corp_vocab,\n",
    "    initial_embedding_dict= original_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newglove = dict(zip(corp_vocab, new_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../out/repo_glove.pkl\",\"wb\")\n",
    "pickle.dump(newglove, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
