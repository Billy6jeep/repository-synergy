## pkulaw_spider
## 爬取北大法宝网http://www.pkulaw.cn/Case/

1.打开网站，导航栏点击司法案例，看左边法律文档按案由分类，可以看见大概一共2kw左右的文书，实时与裁判文书网同步更新。

2.可以看见文书案例顶部有筛选条件，可以按照日期、法院等筛选。（本爬虫按照日期爬取所有的文书）

3.分析网站内容时发现，点击下一页按钮地址栏的链接并无变化，属于动态网页。

4.使用浏览器自带抓包工具或者fidder,点击下一页按钮，查看http请求。

5.发现记录由/Recod传送，该请求即是需要模拟的请求link，使用requests模拟浏览器直接请求数据库，带上浏览器headers和post data

6.分析得到的url，可以发现start和end参数，我们修改其为我们所需的日期范围。

7.pagesize我们设置为1000，太小页数过多，太大网页加载太慢。pageIndex为页号，其它参数默认。

8.模拟请求数据库，得到法律文档标题和id,第一步先save这些数据。

9.接下来我们来分析单个案件文本内容的请求url

10.点击任一个案件的链接，进入页面，分析http请求

11.我们发现_getFulltext请求的response为我们所需的内容（案件文本）,进入getFulltext，http://www.pkulaw.cn/case/FullText/_getFulltext发现并不
12 能返回什么[请求出处],此时查看该请求的headers和data:library=pfnl&gid=1970324872344528&loginSucc=0,只需将data显示的加入url中即可，即http://www.pkulaw.cn/case/FullText/_getFulltext?library=pfnl&gid=1970324872344528&loginSucc=0

13.通过上述url，爬取文书内容。

14.该爬虫是以前无聊写的一个练手程序，最近加了注释上传至github，一为了不使该程序浪费，二可供新手小白参考动态网页的分析，直接分析出数据源请求比
15 使用selenium+phantomJS效率高得多。三可为法律文档研究者提供语料来源借鉴。


# 2017.9.11 更新 
有朋友需求按 案由 爬取文书，因此更新下程序。
# 可根据时间、案由 来爬取文书  
# python crawl_v2.py
# （注意按输入提示格式进行输入）
民事：002
刑事：001
行政：005
知识产权：003
国家赔偿：007
执行：006
（更细的案由可以去官网查看、或留言咨询我）
不使用案由（全部文书）：classcode 输入空（回车）即可

# ---------------------------------------------------
# 2017.9.17 更新
根据需求，增加了按法院级别、关键字来爬取的功能
# python crawl_v3.py
（按提示的格式输入）
1. 输入起始-结束日期 
2. 输入案由编号classcode1: （eg:002(民事),直接输入回车则不考虑案由）
3. 输入法院级别编号classcode3：（eg:02(北京市),直接输入回车则不考虑法院）
4. 输入查询关键字：（eg:离婚，直接输入回车则不考虑关键字）
（ps:案由编号、法院编号 可到北大法宝官网，通过鼠标右击-审查属性查看；若不会查看，请百度或咨询我）
（有bug可留言告知）

# 2018.6.9
有朋友反应爬取的文书不全（一个案件内容太长，会出现...）  
我看了下发现是因为北大法宝网需要登录才能看到案件全文  
之前的cookie为已登录，但一定时间后失效了，现在已经重新更新了cookie（直接重新下载crawl_v3.py，运行即可） 
这种方式（使用我已登录复制出的cookie）只能维持一定时间（时间长cookie失效），如果能有自己的账号密码最好。  
如cookie再失效请留言告知。

# 2018.6.10
按 日期+案由+法院级别+标题关键字+全文关键字 查询爬取  
代码仅供参考，效率和异常处理上并未优化，请自行优化，本项目仅提供指导性方案。  
法律文书涉及一定隐私，仅供学术研究，请勿售卖数据！

# 如项目对您产生了帮助，请star支持！您的认同是我不断进步的动力！！！#
